{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize acquisition functions using torch.optim\n",
    "\n",
    "In this tutorial, we show how to use PyTorch's `optim` module for optimizing BoTorch MC acquisition functions. This is useful if the acquisition function is stochastic in nature (caused by re-sampling the base samples when using the reparameterization trick, or if the model posterior itself is stochastic).\n",
    "\n",
    "*Note:* A pre-packaged, more user-friendly version of the optimization loop we will develop below is contained in the `gen_candidates_torch` function in the `botorch.gen` module. This tutorial should be quite useful if you would like to implement custom optimizers beyond what is contained in `gen_candidates_torch`.\n",
    "\n",
    "As discussed in the [CMA-ES tutorial](./optimize_with_cmaes), for deterministic acquisition functions BoTorch uses quasi-second order methods (such as L-BFGS-B or SLSQP) by default, which provide superior convergence speed in this situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a toy model\n",
    "\n",
    "We'll fit a `SingleTaskGP` model on noisy observations of the function $f(x) = 1 - \\|x\\|_2$ in `d=5` dimensions on the hypercube $[-1, 1]^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, sensorPositions, space, epsilon):\n",
    "        self.radius = 1\n",
    "        self.placeHolders = sensorPositions\n",
    "        self.epsilon = epsilon\n",
    "        self.space = space\n",
    "        # self.SensorPlaceHolderSetup()\n",
    "        \n",
    "    def frange(self, start, stop, step):\n",
    "        steps = []\n",
    "        while start <= stop:\n",
    "            steps.append(start)\n",
    "            start +=step\n",
    "            \n",
    "        return steps\n",
    "\n",
    "    # def SensorPlaceHolderSetup(self):\n",
    "    #     Xs = self.frange(0, self.space[0], self.epsilon)\n",
    "    #     Ys = self.frange(0, self.space[1], self.epsilon)\n",
    "            \n",
    "    #     for x in Xs:\n",
    "    #       for y in Ys:\n",
    "    #         self.placeHolders.append([x, y])\n",
    "\n",
    "    def GetSensorConfiguration(self):\n",
    "        from collections import Counter\n",
    "        sensorLocations, sensorTypes = self.GetSensorLocations()\n",
    "\n",
    "        summaryDict = Counter(sensorTypes)\n",
    "\n",
    "        # TODO: DIFFERENT SENSOR TYPE DEFINITIONS SHOULD BE ADDED HERE:\n",
    "        configurationSummary = []\n",
    "        for key in summaryDict:\n",
    "            if (key == 1):\n",
    "                configurationSummary.append(['motion sensors', summaryDict[key]])\n",
    "\n",
    "            elif (key == 2):\n",
    "                configurationSummary.append(['beacon sensors', summaryDict[key]])\n",
    "\n",
    "        configurationDetails = []\n",
    "        for index, loc in enumerate(sensorLocations):\n",
    "            if (sensorTypes[index] == 1):\n",
    "                configurationDetails.append(tuple([loc, 'kitchen', 'motion sensors']))\n",
    "\n",
    "            elif (sensorTypes[index] == 2):\n",
    "                configurationDetails.append(tuple([loc, 'kitchen', 'beacon sensors']))\n",
    "\n",
    "        return [[configurationSummary, [tuple(configurationDetails)]], self.radius]\n",
    "\n",
    "\n",
    "    def GetSensorLocations(self):\n",
    "        sensorLocations = []\n",
    "        sensorTypes = []\n",
    "        for index, sensorIndicator in enumerate(self.placeHolders):\n",
    "            sensorLocations.append(self.placeHolders[index])\n",
    "\n",
    "            # TODO: DIFFERENT SENSOR TYPE DEFINITIONS SHOULD BE ADDED HERE:\n",
    "            sensorTypes.append(1)\n",
    "\n",
    "\n",
    "        return sensorLocations, sensorTypes\n",
    "\n",
    "\n",
    "class BOVariables:\n",
    "    def __init__(self, Data_path, epsilon, initSensorNum, maxSensorNum, radius, sampleSize):\n",
    "        self.epsilon = epsilon\n",
    "        self.Data_path = Data_path\n",
    "        self.initSensorNum = initSensorNum\n",
    "        self.maxSensorNum = maxSensorNum\n",
    "        self.radius = radius\n",
    "        self.sensor_distribution, self.types, self.space, self.rooms, self.agentTraces = self.ModelsInitializations()\n",
    "\n",
    "    def ModelsInitializations(self):\n",
    "        #----- Space and agent models -----: \n",
    "        simworldname = self.Data_path + '/Configuration Files/simulationWorld2.xml'\n",
    "        agentTraces = []\n",
    "        directory = os.fsencode(self.Data_path + 'Agent Trace Files/')\n",
    "            \n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".csv\"): \n",
    "                agentTraces.append(self.Data_path + 'Agent Trace Files/' + filename)\n",
    "\n",
    "        # Parsing the space model: \n",
    "        space, rooms = pf.ParseWorld(simworldname)\n",
    "\n",
    "        xs = []\n",
    "        for i in space:\n",
    "          for j in i:\n",
    "            xs.append(j)\n",
    "        A = list(set(xs))\n",
    "        A.sort()\n",
    "        space = [A[-1], A[-2]]\n",
    "\n",
    "        # User parameters \n",
    "        types, sensor_distribution = pf.GetUsersParameters()\n",
    "\n",
    "        roomsList = []\n",
    "        for room in sensor_distribution:\n",
    "            roomsList.append(room)\n",
    "              \n",
    "        return sensor_distribution, types, space, rooms, agentTraces\n",
    "\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    steps = []\n",
    "    while start <= stop:\n",
    "        steps.append(start)\n",
    "        start +=step\n",
    "        \n",
    "    return steps\n",
    "\n",
    "def MakeSensorCombinations(start, end, epsilon, sensorType, room):\n",
    "    a1, b1 = makeBoundaries(epsilon, start[0], end[0])\n",
    "    a2, b2 = makeBoundaries(epsilon, start[1], end[1])    \n",
    "    Xs = frange(a1, b1, epsilon)\n",
    "    Ys = frange(a2, b2, epsilon)\n",
    "    \n",
    "    points = list(itertools.product(list(itertools.product(Xs, Ys)), [room], [sensorType[0]])) \n",
    "    C = itertools.combinations(points, distribution[room][types.index(sensorType)])\n",
    "\n",
    "    return C\n",
    "\n",
    "def PreProcessor(df):\n",
    "    # df['motion sensors'] = df['motion sensors'].apply(ast.literal_eval)\n",
    "    df['motion sensors'] = df['motion sensors'].apply(lambda s: list(map(int, s)))\n",
    "    # df['beacon sensors'] = df['beacon sensors'].apply(ast.literal_eval)\n",
    "    try:\n",
    "      df['beacon sensors'] = df['beacon sensors'].apply(lambda s: list(map(int, s)))\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    sensors = set([])\n",
    "\n",
    "    previous_M = None\n",
    "    previous_B = None\n",
    "    output_file = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "      T = row['time']\n",
    "      M = row['motion sensors']\n",
    "      try:\n",
    "        B = row['beacon sensors']\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "      Activity = row['activity']\n",
    "      Activity = Activity.replace(' ', '_')\n",
    "      MotionSensor_Names = []\n",
    "      sensorNames = []\n",
    "      MotionSensor_Message = []\n",
    "      BeaconSensor_Names = []\n",
    "      BeaconSensor_Message = []\n",
    "      \n",
    "\n",
    "      # time = convertTime(T)\n",
    "      time = \"2020-06-16 \" + T + \".00\"\n",
    "\n",
    "      # Motion Sensor\n",
    "      for i in range(len(M)):\n",
    "        sensorNames.append(Name(i, 'M'))\n",
    "        if M[i] == 1:\n",
    "          if (previous_M != None):\n",
    "            if (previous_M[i] == 0):\n",
    "              MotionSensor_Names.append(Name(i,'M'))\n",
    "              MotionSensor_Message.append('ON')\n",
    "\n",
    "          else:\n",
    "            MotionSensor_Names.append(Name(i,'M'))\n",
    "            MotionSensor_Message.append('ON')\n",
    "\n",
    "        if previous_M != None:\n",
    "          if M[i] == 0 and previous_M[i] == 1:\n",
    "            MotionSensor_Names.append(Name(i,'M'))\n",
    "            MotionSensor_Message.append('OFF')\n",
    "\n",
    "      previous_M = M\n",
    "      # Beacon Sensor\n",
    "\n",
    "      try:\n",
    "        for i in range(len(B)):\n",
    "          sensorNames.append(Name(i, 'B'))\n",
    "          if B[i] == 1:\n",
    "            BeaconSensor_Names.append(Name(i,'B'))\n",
    "            BeaconSensor_Message.append('ON')\n",
    "          if previous_B != None:\n",
    "            if B[i] == 0 and previous_B[i] == 1: \n",
    "              BeaconSensor_Names.append(Name(i,'B'))\n",
    "              BeaconSensor_Message.append('OFF')\n",
    "        previous_B = B\n",
    "\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "      for m in range(len(MotionSensor_Names)):\n",
    "        output_file.append(time +' '+ MotionSensor_Names[m] + ' ' + MotionSensor_Names[m] + ' ' + MotionSensor_Message[m] + ' ' + Activity)\n",
    "        \n",
    "      for s in sensorNames:\n",
    "          sensors.add(s)\n",
    "\n",
    "    return output_file, list(sensors)\n",
    "\n",
    "#returns the name of the sensor\n",
    "def Name(number, typeSensor):\n",
    "    if number < 10:\n",
    "      return typeSensor + str(0) + str(number)\n",
    "    else:\n",
    "      return typeSensor + str(number)\n",
    "\n",
    "#converts epoch time to human readable\n",
    "def convertTime(posix_timestamp):\n",
    "    tz = pytz.timezone('MST')\n",
    "    dt = datetime.fromtimestamp(posix_timestamp, tz)\n",
    "    time = dt.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    return time\n",
    "\n",
    "def MakeDataBoundaries(height = 10.5, width = 6.6, MaxSensors = 15):\n",
    "    from collections import defaultdict, OrderedDict\n",
    "\n",
    "    d = dict()\n",
    "\n",
    "    for idx in range(MaxSensors):\n",
    "            d['x' + str(idx)] = (0.5, width - 0.5)\n",
    "            d['y' + str(idx)] = (0.5, height - 0.5)\n",
    "\n",
    "    return d\n",
    "\n",
    "def black_box_function(sample, simulateMotionSensors = True, simulateEstimotes = False, Plotting = False):       \n",
    "    files = []\n",
    "\n",
    "    if (runningOnGoogleColab == True):\n",
    "        sys.path.append('gdrive/My Drive/PhD/Thesis/Ideas/Codes/Sensor Simulator/')\n",
    "        Data_path = 'gdrive/My Drive/PhD/Thesis/Ideas/Codes/Sensor Simulator/'\n",
    "        \n",
    "    else:\n",
    "        sys.path.append('../../Codes/Sensor Simulator/')\n",
    "        Data_path = '../../Codes/Sensor Simulator/'\n",
    "\n",
    "    all_sensors = set([])\n",
    "\n",
    "    for agentTrace in BOV.agentTraces:\n",
    "        df_ = sim_sis.RunSimulator(BOV.space, BOV.rooms, agentTrace, sample.GetSensorConfiguration(), simulateMotionSensors, simulateEstimotes, Plotting, BOV.Data_path)\n",
    "        dataFile, sensors = PreProcessor(df_)\n",
    "        all_sensors.update(sensors)\n",
    "        files.append(dataFile)\n",
    "        \n",
    "    \n",
    "    if (runningOnGoogleColab == True):\n",
    "        sys.path.append('gdrive/My Drive/PhD/Thesis/Ideas/Codes/CASAS/AL-Smarthome')\n",
    "\n",
    "    else:\n",
    "        sys.path.append('../../Codes/CASAS/AL-Smarthome')\n",
    "\n",
    "    import al\n",
    "    import imp\n",
    "    imp.reload(al)\n",
    "    all_sensors = list(all_sensors)\n",
    "\n",
    "    accuracy = (al.leave_one_out(files, all_sensors)[0]) * 100\n",
    "\n",
    "    if accuracy < 0:\n",
    "        accuracy = 0\n",
    "\n",
    "    return [accuracy]\n",
    "\n",
    "def function_to_be_optimized(T):\n",
    "    sensorPositions = []\n",
    "    sensor_xy = []\n",
    "    for i, item in enumerate(T):\n",
    "            if i % 2 == 0:\n",
    "                sensor_xy.append(item)\n",
    "\n",
    "            else:\n",
    "                sensor_xy.append(item)  \n",
    "                sensorPositions.append(sensor_xy)\n",
    "                sensor_xy = []\n",
    "\n",
    "    data = Data(sensorPositions, BOV.space, CONSTANTS['epsilon'])\n",
    "    return torch.Tensor(black_box_function(data))\n",
    "\n",
    "def InitializeX(BOV, init_num):\n",
    "    train_x = []\n",
    "    for i in range(init_num):\n",
    "        Xs = frange(0, BOV.space[0], BOV.epsilon)\n",
    "        Ys = frange(0, BOV.space[1], BOV.epsilon)\n",
    "        grid = np.zeros(len(Xs) * len(Ys)).tolist()\n",
    "        placeHolders = []\n",
    "\n",
    "\n",
    "        for x in Xs:\n",
    "            for y in Ys:\n",
    "                placeHolders.append([x, y])\n",
    "\n",
    "        i = 0\n",
    "        while i < BOV.initSensorNum:\n",
    "            cell = random.randrange(len(grid))\n",
    "            if grid[cell] == 0:\n",
    "                grid[cell] = 1\n",
    "                i += 1\n",
    "\n",
    "        sensorPositions = []\n",
    "        sensorTypes = []\n",
    "        for index, sensorIndicator in enumerate(grid):\n",
    "            if (sensorIndicator > 0):\n",
    "                # sensorPositions.append(torch.Tensor(placeHolders[index]))\n",
    "                sensorPositions.append(placeHolders[index][0])\n",
    "                sensorPositions.append(placeHolders[index][1])\n",
    "                sensorTypes.append(torch.Tensor(sensorIndicator))\n",
    "\n",
    "        sensorPositions = torch.Tensor(sensorPositions)\n",
    "        # data = Data(sensorPositions, BOV.space, epsilon)\n",
    "        train_x.append(sensorPositions)\n",
    "\n",
    "    train_x = torch.stack(train_x)\n",
    "    \n",
    "    return train_x\n",
    "\n",
    "def InitializeY(BOV, train_x):\n",
    "    train_y = []\n",
    "\n",
    "    sensorPositions = []\n",
    "    sensor_xy = []\n",
    "    for T in train_x:\n",
    "        for i, item in enumerate(T):\n",
    "            if i % 2 == 0:\n",
    "                sensor_xy.append(item)\n",
    "\n",
    "            else:\n",
    "                sensor_xy.append(item)  \n",
    "                sensorPositions.append(sensor_xy)\n",
    "                sensor_xy = []\n",
    "\n",
    "        data = Data(sensorPositions, BOV.space, CONSTANTS['epsilon'])\n",
    "        train_y.append(torch.Tensor(black_box_function(data)))\n",
    "\n",
    "    train_y = torch.stack(train_y)\n",
    "    \n",
    "    return train_y\n",
    "\n",
    "def InitializeDataset(BOV, init_num = 5):\n",
    "    train_x = InitializeX(BOV, init_num)\n",
    "    train_y = InitializeY(BOV, train_x)\n",
    "    best_observed_value = train_y.max()\n",
    "\n",
    "    return train_x, train_y, best_observed_value\n",
    "    \n",
    "\n",
    "def frange(start, stop, step):\n",
    "    steps = []\n",
    "    while start <= stop:\n",
    "        steps.append(start)\n",
    "        start +=step\n",
    "        \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTANTS = {\n",
    "    'iterations': 100,\n",
    "    'initial_samples': 1,\n",
    "    'restarts_number': 10,\n",
    "    'raw_samples': 10,\n",
    "    'candidates_num': 11,\n",
    "    'sequential': True,\n",
    "    'epsilon': 1,\n",
    "    'radius': 1,\n",
    "    'height': 10.5,\n",
    "    'width': 6.6,\n",
    "    'max_sensors': 15  \n",
    "}\n",
    "\n",
    "runningOnGoogleColab = False\n",
    "    \n",
    "if __name__ ==  '__main__':\n",
    "    import sys\n",
    "\n",
    "    if (runningOnGoogleColab == True):\n",
    "        from google.colab import drive    \n",
    "        drive.mount('/content/gdrive', force_remount=True)\n",
    "        Data_path = 'gdrive/My Drive/PhD/Thesis/Ideas/Codes/Sensor Simulator/'\n",
    "        sys.path.append('gdrive/My Drive/PhD/Thesis/Ideas/Codes/Sensor Simulator/')\n",
    "        \n",
    "    else:\n",
    "        Data_path = '../../Codes/Sensor Simulator/'\n",
    "        sys.path.append('../../Codes/Sensor Simulator/')\n",
    "\n",
    "    # from ax import optimize, ChoiceParameter\n",
    "    from scipy.stats import norm\n",
    "    from numpy import argmax\n",
    "    import SIM_SIS_Libraries.SensorsClass\n",
    "    import SIM_SIS_Libraries.SIM_SIS_Simulator as sim_sis\n",
    "    import SIM_SIS_Libraries.ParseFunctions as pf\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import SIM_SIS_Libraries.PreDeploymentEvaluation as pde\n",
    "    import copy\n",
    "    from datetime import datetime\n",
    "    import pytz\n",
    "    import ast\n",
    "    import os\n",
    "    import random\n",
    "    import plotly\n",
    "    import torch\n",
    "\n",
    "    from botorch.models import SingleTaskGP, ModelListGP\n",
    "    from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "    from botorch import fit_gpytorch_model\n",
    "    from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "    from botorch.optim import optimize_acqf\n",
    "\n",
    "    finalResults = []\n",
    "    w = CONSTANTS['width'] - 0.5\n",
    "    h = CONSTANTS['height'] - 0.5\n",
    "\n",
    "    dataBoundaries = MakeDataBoundaries(\n",
    "                                        height = CONSTANTS['height'], \n",
    "                                        width = CONSTANTS['width'], \n",
    "                                        MaxSensors = CONSTANTS['max_sensors']\n",
    "                                       )\n",
    "\n",
    "    BOV =  BOVariables(\n",
    "                       Data_path, \n",
    "                       CONSTANTS['epsilon'], \n",
    "                       CONSTANTS['max_sensors'], \n",
    "                       CONSTANTS['max_sensors'], \n",
    "                       CONSTANTS['radius'],\n",
    "                       CONSTANTS['initial_samples']\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): GammaPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): GammaPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "        (distance_module): Distance()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = CONSTANTS['max_sensors'] * 2\n",
    "\n",
    "train_X, train_Y, bestResult = InitializeDataset(BOV, 2)\n",
    "\n",
    "model = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define acquisition function\n",
    "\n",
    "We'll use `qExpectedImprovement` with a custom sampler that uses a small number of MC samples and re-samples upon each evaluation of the function. This results in a stochastic acquisition function that one should not attempt to optimize with the quasi-second order methods that are used by default in BoTorch's `joint_optimize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.sampling import IIDNormalSampler\n",
    "\n",
    "sampler = IIDNormalSampler(num_samples=100, resample=True)\n",
    "qEI = qExpectedImprovement(model, best_f=train_Y.max(), sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the acquisition function\n",
    "\n",
    "We will perform optimization over `N=5` random initial `q`-batches with `q=2` in parallel. We use `N` random restarts because the acquisition function is non-convex and as a result we may get stuck in local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "q = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing initial conditions via a heuristic\n",
    "\n",
    "Using random initial conditions in conjunction with gradient-based optimizers can be problematic because qEI values and their corresponding gradients are often zero in large parts of the feature space. To mitigate this issue, BoTorch provides a heuristic for generating promising initial conditions (this dirty and not-so-little secret of Bayesian Optimization is actually very important for overall closed-loop performance).\n",
    "\n",
    "Given a set of `q`-batches $X'$ and associated acquisiton function values $Y'$, the `initialize_q_batch_nonneg` samples promising initial conditions $X$ (without replacement) from the multinomial distribution\n",
    "\n",
    "$$ \\mathbb{P}(X = X'_i) \\sim \\exp (\\eta \\tilde{Y}_i), \\qquad \\text{where} \\;\\; \\tilde{Y}_i = \\frac{Y'_i - \\mu(Y)}{\\sigma(Y)} \\;\\; \\text{if} \\;\\; Y'_i >0 $$\n",
    "\n",
    "and $\\mathbb{P}(X = X'_j) = 0$ for all $j$ such that $Y'_j = 0$. \n",
    "\n",
    "Fortunately, thanks to the high degree of parallelism in BoTorch, evaluating the acquisition function at a large number of randomly chosen points is quite cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 30])\n"
     ]
    }
   ],
   "source": [
    "from botorch.optim.initializers import initialize_q_batch_nonneg\n",
    "\n",
    "# generate a large number of random q-batches\n",
    "t = InitializeX(BOV, 100 * N)\n",
    "print(t.shape)\n",
    "Xraw = torch.reshape(t, (-1,q,d))\n",
    "\n",
    "#Xraw = bounds[0] + (bounds[1] - bounds[0]) * torch.rand(100 * N, q, d)\n",
    "Yraw = qEI(Xraw)  # evaluate the acquisition function on these q-batches\n",
    "\n",
    "# apply the heuristic for sampling promising initial conditions\n",
    "X = initialize_q_batch_nonneg(Xraw, Yraw, N)\n",
    "\n",
    "# we'll want gradients for the input\n",
    "X.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing the acquisition function\n",
    "\n",
    "If you have used PyTorch, the basic optimization loop should be quite familiar. However, it is important to note that there is a **key difference** here compared to training ML models: When training ML models, one typically computes the gradient of an empirical loss function w.r.t. the model's parameters, while here we take the gradient of the acquisition function w.r.t. to the candidate set.\n",
    "\n",
    "Thus, when setting the optimizer from `torch.optim`, we **do not** add the acquisition function's parameters as parameters to optimize (that would be quite bad!).\n",
    "\n",
    "In this example, we use a vanilla `Adam` optimizer with fixed learning rate for a fixed number of iterations in order to keep things simple. But you can get as fancy as you want with learning rate scheduling, early termination, etc.\n",
    "\n",
    "A couple of things to note:\n",
    "1. Evaluating the acquisition function on the `N x q x d`-dim inputs means evaluating `N` `q`-batches in `t`-batch mode. The result of this is an `N`-dim tensor of acquisition function values, evaluated independently. To compute the gradient of the full input `X` via back-propagation, we can for convenience just compute the gradient of the sum of the losses. \n",
    "2. `torch.optim` does not have good built in support for constraints (general constrained stochastic optimization is hard and still an open research area). Here we do something simple and project the value obtained after taking the gradient step to the feasible set - that is, we perform \"projected stochastic gradient descent\". Since the feasible set here is a hyperrectangle, this can be done by simple clamping. Another approach would be to transform the feasible interval for each dimension to the real line, e.g. by using a sigmoid function, and then optimizing in the unbounded transformed space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  15/75 - Loss: -2.434\n",
      "Iteration  30/75 - Loss: -2.233\n",
      "Iteration  45/75 - Loss: -2.399\n",
      "Iteration  60/75 - Loss: -2.427\n",
      "Iteration  75/75 - Loss: -2.697\n",
      "Iteration  90/75 - Loss: -2.861\n"
     ]
    }
   ],
   "source": [
    "# set up the optimizer, make sure to only pass in the candidate set here\n",
    "optimizer = torch.optim.Adam([X], lr=0.01)\n",
    "X_traj = []  # we'll store the results\n",
    "\n",
    "# run a basic optimization loop\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    # this performs batch evaluation, so this is an N-dim tensor\n",
    "    losses = - qEI(X)  # torch.optim minimizes\n",
    "    loss = losses.sum()\n",
    "    \n",
    "    loss.backward()  # perform backward pass\n",
    "    optimizer.step()  # take a step\n",
    "    \n",
    "    # clamp values to the feasible set\n",
    "    for j, (lb, ub) in enumerate(zip(*bounds)):\n",
    "        X.data[..., j].clamp_(lb, ub) # need to do this on the data not X itself\n",
    "    \n",
    "    # store the optimization trajecatory\n",
    "    X_traj.append(X.detach().clone())\n",
    "    \n",
    "    if (i + 1) % 15 == 0:\n",
    "        print(f\"Iteration {i+1:>3}/75 - Loss: {loss.item():>4.3f}\")\n",
    "    \n",
    "    # use your favorite convergence criterion here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4209e-09, -2.3675e-01, -2.3675e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00, -2.3675e-01,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "         [-3.4209e-09,  1.0000e+00,  1.0000e+00, -2.3960e-01,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.3960e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          -2.3749e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.4042e-01,  1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[-2.5401e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.5401e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00, -2.5451e-01,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          -2.5451e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.0000e+00, -2.5401e-01,  1.0000e+00,\n",
       "          -2.5401e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[-3.4209e-09, -2.6070e-01, -2.6070e-01,  1.0000e+00, -2.6070e-01,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.5968e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00, -2.5968e-01,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "         [-3.4209e-09,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00, -2.6070e-01,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[-2.8238e-01, -2.8307e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          -2.8296e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "         [ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.8262e-01,  1.0000e+00, -2.8307e-01,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00, -2.4995e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
       "         [-2.4947e-01,  1.0000e+00,  1.0000e+00, -2.5100e-01,  1.0000e+00,\n",
       "          -2.5100e-01,  1.0000e+00, -2.5100e-01,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          -2.5100e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_traj[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100-5-2-30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
